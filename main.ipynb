{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install demoji"
      ],
      "metadata": {
        "id": "Ck8zNj2W2zCG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk\n",
        "# nltk.download(\"stopwords\")\n",
        "# nltk.download(\"wordnet\")\n",
        "\n",
        "import polars as pl\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import demoji"
      ],
      "metadata": {
        "id": "XYchABerxjX_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "351e7917-9d85-4370-f808-801acdaf63c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a5b819147b0a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdemoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'demoji'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Stopwords and the dataset\n",
        "ensw = stopwords.words('english')\n",
        "\n",
        "df = pl.read_csv(\"dataset.csv\")"
      ],
      "metadata": {
        "id": "PwhDSfdD1e3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean ID Part\n",
        "df = df.select([\n",
        "    pl.col(\"ID\").apply(lambda id: id.split(\"-\")[1]).cast(pl.Int32),\n",
        "    pl.exclude(\"ID\")\n",
        "])"
      ],
      "metadata": {
        "id": "fiOIL7641mOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows without tweet AND tweet URL\n",
        "df = df.filter(pl.col(\"Tweet\").is_not_null() & pl.col(\"Tweet URL\").is_not_null())"
      ],
      "metadata": {
        "id": "Q6wB0hFB1uhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Include only necessary columns\n",
        "df = df.select(\n",
        "    pl.col(\"ID\"),\n",
        "    pl.col(\"Tweet\"),\n",
        "    pl.col(\"Tweet Translated\").alias(\"Translated\")\n",
        ")"
      ],
      "metadata": {
        "id": "ocQIJeC_1wyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change tweet case to lowercase\n",
        "df = df.select(\n",
        "    pl.all(),\n",
        "    pl.col(\"Translated\").apply(lambda tweet: tweet.lower()).alias(\"Clean\")\n",
        ")"
      ],
      "metadata": {
        "id": "SEX6abSJ1zKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove hashtags\n",
        "df = df.select(\n",
        "    pl.exclude(\"Clean\"),\n",
        "    pl.col(\"Clean\").apply(lambda tweet: re.sub(\"#(\\w+)\", '', tweet))\n",
        ")"
      ],
      "metadata": {
        "id": "xxWn2UW4_WNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace all emojis into interpretation\n",
        "def emoji_to_word(tweet):\n",
        "  for symbol, interpretation in demoji.findall(tweet).items():\n",
        "    interpretation = interpretation.lower()\n",
        "    # Turn flag: Philippines into flagphilippines \n",
        "    interpretation = re.sub('[^0-9a-z]+', '', interpretation)\n",
        "    # replace all emojis to \"emojiinterpretation \"\n",
        "    tweet = re.sub(symbol, interpretation+' ', tweet)\n",
        "  return tweet\n",
        "\n",
        "df = df.select(\n",
        "    pl.exclude(\"Clean\"),\n",
        "    pl.col(\"Clean\").apply(emoji_to_word)\n",
        ")"
      ],
      "metadata": {
        "id": "SN_0gMLh8HWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove non alphanumeric characters\n",
        "df = df.select(\n",
        "    pl.exclude(\"Clean\"),\n",
        "    pl.col(\"Clean\").apply(lambda tweet: re.sub('[^0-9a-z]+', ' ', tweet))\n",
        ")"
      ],
      "metadata": {
        "id": "VCfJ-Nqq7LD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cast Tweets to word array instead of long string.\n",
        "df = df.select(\n",
        "    pl.all(),\n",
        "    pl.col(\"Clean\").apply(lambda tweet: tweet.split()).cast(pl.List(str)).alias(\"Tokenized\")\n",
        ")"
      ],
      "metadata": {
        "id": "GSnfF1n210yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip english stopwords\n",
        "df = df.select(\n",
        "    pl.all(),\n",
        "    pl.col(\"Tokenized\").arr.eval(pl.element().filter(~pl.element().is_in(ensw)), parallel=True).alias(\"Stopwords Removed\")\n",
        ")"
      ],
      "metadata": {
        "id": "zGwZCcBN12QZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ed5db31e-1f75-4119-94f8-a13b010beba6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2bb2e6dc6d71>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Strip english stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m df = df.select(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokenized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stopwords Removed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stem and Lemmatize.\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Initialize the stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "df = df.select(\n",
        "    pl.all(),\n",
        "    pl.col(\"Stopwords Removed\").apply(lambda words: [stemmer.stem(word) for word in words.to_list()]).alias(\"Stemmed\"),\n",
        "    pl.col(\"Stopwords Removed\").apply(lambda words: [lemmatizer.lemmatize(word) for word in words.to_list()]).alias(\"Lemmatized\")\n",
        ")"
      ],
      "metadata": {
        "id": "6sjGF58uBU36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)\n",
        "def serialize(arr):\n",
        "  return \" \".join(arr)\n",
        "df_serialized = df.select(\n",
        "    pl.col(\"ID\"),\n",
        "    pl.col(\"Tweet\"),\n",
        "    pl.col(\"Translated\"),\n",
        "    pl.col(\"Clean\"),\n",
        "    pl.col(\"Tokenized\").apply(serialize).cast(str),\n",
        "    pl.col(\"Stopwords Removed\").apply(serialize).cast(str),\n",
        "    pl.col(\"Stemmed\").apply(serialize).cast(str),\n",
        "    pl.col(\"Lemmatized\").apply(serialize).cast(str)\n",
        ")\n",
        "df_serialized.write_csv(\"clean.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGcYfwPM16OT",
        "outputId": "e8a94e34-0e8e-4f00-c4c0-7ba64d5f3480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (153, 8)\n",
            "┌─────┬─────────────┬─────────────┬────────────┬────────────┬────────────┬────────────┬────────────┐\n",
            "│ ID  ┆ Tweet       ┆ Translated  ┆ Clean      ┆ Tokenized  ┆ Stopwords  ┆ Stemmed    ┆ Lemmatized │\n",
            "│ --- ┆ ---         ┆ ---         ┆ ---        ┆ ---        ┆ Removed    ┆ ---        ┆ ---        │\n",
            "│ i32 ┆ str         ┆ str         ┆ str        ┆ list[str]  ┆ ---        ┆ list[str]  ┆ list[str]  │\n",
            "│     ┆             ┆             ┆            ┆            ┆ list[str]  ┆            ┆            │\n",
            "╞═════╪═════════════╪═════════════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n",
            "│ 1   ┆ Cory        ┆ Cory        ┆ cory       ┆ [\"cory\",   ┆ [\"cory\",   ┆ [\"cori\",   ┆ [\"cory\",   │\n",
            "│     ┆ Aquino: \r    ┆ Aquino:\r     ┆ aquino     ┆ \"aquino\",  ┆ \"aquino\",  ┆ \"aquino\",  ┆ \"aquino\",  │\n",
            "│     ┆ - Duly      ┆ - Duly      ┆ duly       ┆ … \"fact\"]  ┆ … \"fact\"]  ┆ … \"fact\"]  ┆ … \"fact\"]  │\n",
            "│     ┆ elected Pr… ┆ elected     ┆ elected    ┆            ┆            ┆            ┆            │\n",
            "│     ┆             ┆ pre…        ┆ preside…   ┆            ┆            ┆            ┆            │\n",
            "│ 2   ┆ Ninoy       ┆ Ninoy       ┆ ninoy      ┆ [\"ninoy\",  ┆ [\"ninoy\",  ┆ [\"ninoy\",  ┆ [\"ninoy\",  │\n",
            "│     ┆ Aquino is a ┆ Aquino is a ┆ aquino is  ┆ \"aquino\",  ┆ \"aquino\",  ┆ \"aquino\",  ┆ \"aquino\",  │\n",
            "│     ┆ TRAITOR.\r    ┆ TRAITOR.\r    ┆ a traitor  ┆ …          ┆ …          ┆ …          ┆ …          │\n",
            "│     ┆ \r            ┆ \r            ┆ he joi…    ┆ \"family\"]  ┆ \"family\"]  ┆ \"famili\"]  ┆ \"family\"]  │\n",
            "│     ┆ He…         ┆ He…         ┆            ┆            ┆            ┆            ┆            │\n",
            "│ 3   ┆ Ninoy is a  ┆ Ninoy is a  ┆ ninoy is a ┆ [\"ninoy\",  ┆ [\"ninoy\",  ┆ [\"ninoy\",  ┆ [\"ninoy\",  │\n",
            "│     ┆ traitor, an ┆ traitor, an ┆ traitor an ┆ \"is\", …    ┆ \"traitor\", ┆ \"traitor\", ┆ \"traitor\", │\n",
            "│     ┆ idiot and…  ┆ idiot and…  ┆ idiot and  ┆ \"etc\"]     ┆ … \"etc\"]   ┆ … \"etc\"]   ┆ … \"etc\"]   │\n",
            "│     ┆             ┆             ┆ …          ┆            ┆            ┆            ┆            │\n",
            "│ 4   ┆ Ninoy       ┆ Ninoy       ┆ ninoy      ┆ [\"ninoy\",  ┆ [\"ninoy\",  ┆ [\"ninoy\",  ┆ [\"ninoy\",  │\n",
            "│     ┆ Aquino day  ┆ Aquino day  ┆ aquino day ┆ \"aquino\",  ┆ \"aquino\",  ┆ \"aquino\",  ┆ \"aquino\",  │\n",
            "│     ┆ should be   ┆ should be   ┆ should be  ┆ … \"inc\"]   ┆ … \"inc\"]   ┆ … \"inc\"]   ┆ … \"inc\"]   │\n",
            "│     ┆ aboli…      ┆ aboli…      ┆ aboli…     ┆            ┆            ┆            ┆            │\n",
            "│ …   ┆ …           ┆ …           ┆ …          ┆ …          ┆ …          ┆ …          ┆ …          │\n",
            "│ 150 ┆ Ninoy is    ┆ Ninoy is    ┆ ninoy is   ┆ [\"ninoy\",  ┆ [\"ninoy\",  ┆ [\"ninoy\",  ┆ [\"ninoy\",  │\n",
            "│     ┆ not worth   ┆ not worth   ┆ not worth  ┆ \"is\", …    ┆ \"worth\", … ┆ \"worth\", … ┆ \"worth\", … │\n",
            "│     ┆ dying       ┆ Dying       ┆ dying for  ┆ \"bonifacio ┆ \"bonifacio ┆ \"bonifacio ┆ \"bonifacio │\n",
            "│     ┆ for,but…    ┆ for,but…    ┆ but…       ┆ \"]         ┆ \"…         ┆ \"…         ┆ \"…         │\n",
            "│ 151 ┆ common,     ┆ common,     ┆ common     ┆ [\"common\", ┆ [\"common\", ┆ [\"common\", ┆ [\"common\", │\n",
            "│     ┆ ninoy is    ┆ ninoy is    ┆ ninoy is   ┆ \"ninoy\", … ┆ \"ninoy\", … ┆ \"ninoy\", … ┆ \"ninoy\", … │\n",
            "│     ┆ big traitor ┆ big traitor ┆ big        ┆ \"rollingon ┆ \"rollingon ┆ \"rollingon ┆ \"rollingon │\n",
            "│     ┆ and…        ┆ and…        ┆ traitor    ┆ …          ┆ …          ┆ …          ┆ …          │\n",
            "│     ┆             ┆             ┆ and …      ┆            ┆            ┆            ┆            │\n",
            "│ 152 ┆ npa founder ┆ npa founder ┆ npa        ┆ [\"npa\",    ┆ [\"npa\",    ┆ [\"npa\",    ┆ [\"npa\",    │\n",
            "│     ┆ 😎          ┆ 😎          ┆ founder    ┆ \"founder\", ┆ \"founder\", ┆ \"founder\", ┆ \"founder\", │\n",
            "│     ┆             ┆             ┆ smilingfac ┆ \"smilingfa ┆ \"smilingfa ┆ \"smilingfa ┆ \"smilingfa │\n",
            "│     ┆             ┆             ┆ ewithsungl ┆ cew…       ┆ cew…       ┆ cew…       ┆ cew…       │\n",
            "│     ┆             ┆             ┆ …          ┆            ┆            ┆            ┆            │\n",
            "│ 153 ┆ They        ┆ They        ┆ they       ┆ [\"they\",   ┆ [\"think\",  ┆ [\"think\",  ┆ [\"think\",  │\n",
            "│     ┆ couldn't    ┆ couldn't    ┆ couldn t   ┆ \"couldn\",  ┆ \"better\",  ┆ \"better\",  ┆ \"better\",  │\n",
            "│     ┆ think of a  ┆ think of a  ┆ think of a ┆ … \"truth\"] ┆ … \"truth\"] ┆ … \"truth\"] ┆ … \"truth\"] │\n",
            "│     ┆ better …    ┆ better …    ┆ better …   ┆            ┆            ┆            ┆            │\n",
            "└─────┴─────────────┴─────────────┴────────────┴────────────┴────────────┴────────────┴────────────┘\n"
          ]
        }
      ]
    }
  ]
}